#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>

#define N (1 << 16) // 2^16 elements

void daxpy_serial(double a, double *X, double *Y) {
    for (int i = 0; i < N; i++) {
        X[i] = a * X[i] + Y[i];
    }
}

int main(int argc, char *argv[]) {
    int rank, size;
    double a = 2.5; // Scalar multiplier
    double *X = NULL, *Y = NULL;
    double *local_X, *local_Y;
    int local_N;
    double start, end, serial_time, parallel_time;

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    local_N = N / size;
    local_X = (double *)aligned_alloc(64, local_N * sizeof(double)); // Use aligned memory
    local_Y = (double *)aligned_alloc(64, local_N * sizeof(double));

    // Use root process to initialize data
    if (rank == 0) {
        X = (double *)aligned_alloc(64, N * sizeof(double));
        Y = (double *)aligned_alloc(64, N * sizeof(double));
        for (int i = 0; i < N; i++) {
            X[i] = i * 1.0;
            Y[i] = (i + 1) * 1.0;
        }

        // Measure serial execution time
        start = MPI_Wtime();
        daxpy_serial(a, X, Y);
        end = MPI_Wtime();
        serial_time = end - start;
        printf("Serial Execution Time: %f seconds\n", serial_time);
    }

    // Scatter X and Y using MPI_Scatterv for better load balancing
    MPI_Scatter(X, local_N, MPI_DOUBLE, local_X, local_N, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    MPI_Scatter(Y, local_N, MPI_DOUBLE, local_Y, local_N, MPI_DOUBLE, 0, MPI_COMM_WORLD);

    // Synchronize before starting computation
    MPI_Barrier(MPI_COMM_WORLD);
    start = MPI_Wtime();

    // Vectorized DAXPY computation using loop unrolling
    for (int i = 0; i < local_N; i += 4) { 
        local_X[i] = a * local_X[i] + local_Y[i];
        local_X[i + 1] = a * local_X[i + 1] + local_Y[i + 1];
        local_X[i + 2] = a * local_X[i + 2] + local_Y[i + 2];
        local_X[i + 3] = a * local_X[i + 3] + local_Y[i + 3];
    }

    MPI_Barrier(MPI_COMM_WORLD);
    end = MPI_Wtime();
    parallel_time = end - start;

    // Gather the results
    MPI_Gather(local_X, local_N, MPI_DOUBLE, X, local_N, MPI_DOUBLE, 0, MPI_COMM_WORLD);

    // Compute speedup
    if (rank == 0) {
        printf("Parallel Execution Time: %f seconds\n", parallel_time);
        printf("Speedup: %f\n", serial_time / parallel_time);
        free(X);
        free(Y);
    }

    free(local_X);
    free(local_Y);

    MPI_Finalize();
    return 0;
}
